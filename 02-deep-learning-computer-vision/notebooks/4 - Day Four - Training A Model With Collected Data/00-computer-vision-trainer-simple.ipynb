{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision Simplified Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is modified from the `00-computer-vision-trainer.ipynb` notebook and has the explanation text removed\n",
    "\n",
    "The basic steps we'll take are:\n",
    "\n",
    "1. Importing our collected, organized, and cleaned images\n",
    "1. Fine-tune a pretrained neural network model to take images as inputs and output category labels\n",
    "1. Try running this model on a picture from our test dataset and see if it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP HERE, THIS IS THE BASE TRAINER, MAKE A COPY AND DO YOUR WORK THERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what you want to do for this training here:\n",
    "\n",
    "Item Transforms:\n",
    "\n",
    "Batch Transforms:\n",
    "\n",
    "Pre-Trained Model: \n",
    "\n",
    "Batch Size:  \n",
    "\n",
    "Validation Size: \n",
    "\n",
    "Epochs: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 0: Ensure you are running this notebook within a Docker Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Import the image data to the workspace so we can use them to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define the path to the zip file and the extraction directory\n",
    "zip_file_name = 'TRAINING_DATA' # You will want to change this filename to the filename of your data\n",
    "\n",
    "zip_file_path = f\"/workspace/data/{zip_file_name}.zip\" # You should not need to edit anything here because the zip_file_path references the variable containing the filename above, this code assumes it will be a zip file\n",
    "extract_to_dir = '/workspace/data/' # This is where the extracted zip file will go, turning that one zip file into the directories and images files that we will need to work with for training\n",
    "\n",
    "# Check if the TRAINING_DATA directory already exists\n",
    "if not os.path.exists(extract_to_dir+zip_file_name): # If the directory with the real data doesn't exist, run the code inside this if statement. \n",
    "    # Create the extraction directory if it doesn't exist\n",
    "    os.makedirs(extract_to_dir, exist_ok=True) # Since the directory does not exist, it needs to be created\n",
    "\n",
    "    # Open the zip file and extract its contents\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref: # These two lines extract the data from the zip file, and place them in the defined path for the extract_to_dir variable\n",
    "        zip_ref.extractall(extract_to_dir)\n",
    "\n",
    "    print(f\"Extracted all files to {extract_to_dir}\") # Recall that print statments can be very useful, this print statement let's you know that the extraction process has completed\n",
    "else: # This else block will only run if the directory with the real data already exists. If you need to unzip the data again, you will have to remove this directory inside the /workspace/data/ directory\n",
    "    print(f\"Directory {extract_to_dir}{zip_file_name} already exists. Skipping extraction.\") # Since this block only runs if the directory already exists, it's helpful to get a message that it's already there\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train an initial model so that we clean our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/workspace/data/TRAINING_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER\n",
    "# only run this test if you've added new data to the training data\n",
    "# it does NOT need to be run if you're confident that the image files are valid \n",
    "failed = verify_images(get_image_files(path)) # this looks at all of the files in our defined path and verifies that they are images, and failures will be placed in the failed variable\n",
    "failed.map(Path.unlink) # if there are any failes that were not images, remove them from the data\n",
    "len(failed) # show the number of failed files, ideally this will be 0, but even if it's more than 0 know that those files are now gone and we don't need to worry about them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(224, 'squish'),#RandomResizedCrop(224, min_scale=0.3),\n",
    "    batch_tfms=aug_transforms()\n",
    ").dataloaders(path, bs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=8, nrows=2, ncols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('levit*', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name\n",
    "model_name = 'levit_384.fb_dist_in1k'\n",
    "\n",
    "# Create the model instance\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "# Retrieve the default configuration\n",
    "default_cfg = model.default_cfg\n",
    "print(default_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find() # find the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00173780077602714 # use the value from the lr_find() method above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_training_epochs = 5\n",
    "learn.fine_tune(initial_training_epochs, base_lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Let's see how our model did and what it had the most difficulty with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(normalize=True, title='Confusion Matrix', figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = 'yarrow.jpg'\n",
    "img_path = f\"/workspace/images/TEST_IMAGES/{img_file}\"\n",
    "Image.open(img_path).to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category,_,probs = learn.predict(PILImage.create(img_path))\n",
    "print(f\"This is a: {category}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Let's clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.widgets import ImageClassifierCleaner\n",
    "cleaner = ImageClassifierCleaner(learn)\n",
    "cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n",
    "for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('/workspace/models/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Now We Train A Model Using What We've Learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first set how often the model should save a checkpoint file, these will be stored as .pth files, not .pkl\n",
    "# not that .pth files will contain the model architecture, whereas .pkl files do not, which means .pth files are much larger in size\n",
    "last_epoch_save = 0 # leave this value as zero if you are starting over from cleaned data\n",
    "save_after_this_many_epochs = 5 # a .pth checkpoint file will be created every 5 epochs\n",
    "model = resnet34\n",
    "path = '/workspace/data/TRAINING_DATA' # ensure this points to your data\n",
    "# Define the number of additional epochs you want to train for\n",
    "additional_epochs = 20  # Set the total number of epochs to run in the cell below\n",
    "learning_rate = 0.0020892962347716093 # use the value from the lr_find() method above\n",
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(224, 'squish'),#RandomResizedCrop(224, min_scale=0.3),\n",
    "    batch_tfms=aug_transforms()\n",
    ").dataloaders(path, bs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.callback.core import Callback\n",
    "from fastai.learner import load_learner\n",
    "from fastai.data.core import DataLoaders\n",
    "\n",
    "# SaveModelCallback will be triggered on each epoch, The default is 10 epochs, but you can set the amount using the save_after_this_many_epochs variable\n",
    "class SaveModelCallback(Callback):\n",
    "    def __init__(self, every=10, path='model', last_epoch_save=0):\n",
    "        self.every = every\n",
    "        self.path = path\n",
    "        self.last_epoch_save = last_epoch_save\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Save the model every `self.every` epochs\"\n",
    "        if (self.epoch + 1) % self.every == 0:\n",
    "            self.learn.save(f'{self.path}_epoch{self.epoch + (1+self.last_epoch_save)}')\n",
    "\n",
    "# Define your data recover function, this function will return .pkl model from one of your checkpoint save files in the .pth format\n",
    "# path = the path to your data (e.g. /workspace/data/TRAINING_DATA), path_to_pth_model = the path to your last saved .pth file\n",
    "def recover_dl_from_pth(path, path_to_pth_model):\n",
    "    dls = ImageDataLoaders.from_folder(path)\n",
    "    learn = cnn_learner(dls, model) # be sure to use the same pretrained model here that you did for previous training, the model variable set above\n",
    "    learn.load(path_to_pth_model)  # Load the model from the .pth file into the learn variable\n",
    "    return learn # return the learn variable\n",
    "\n",
    "# Load the previously trained model\n",
    "recover_from_pth_file = False\n",
    "\n",
    "if(recover_from_pth_file):\n",
    "    # The code below will create a learner recovered from a checkpoint save\n",
    "    # You will want to make sure that the pretrained model in recover_dl_from_pth() the same as what was used for fine tuning earlier\n",
    "    learn_long = recover_dl_from_pth(path, '/workspace/models/model_epochEPOCH_NUM_HERE_TO_GET_TO_CORRECT_FLE.pth')\n",
    "else:\n",
    "    # This code will start at 0 or recover from a .pkl file\n",
    "    if(last_epoch_save > 0):\n",
    "        previous_model_path = '/workspace/models/MODEL_FILENAME.pkl'  # replace with your actual model path\n",
    "        learn_long = load_learner(previous_model_path) #note that this is creating a different learner than the one we used above\n",
    "    else:\n",
    "        learn_long = vision_learner(dls, model, metrics=error_rate) # create the learner\n",
    "    # Ensure data loaders are set up\n",
    "    learn_long.dls = dls # path is the path to our data, which was set earlier\n",
    "\n",
    "# Instantiate the custom callback\n",
    "# modify last_epoch_save to be the number of epochs the model was trained up to\n",
    "save_model_callback = SaveModelCallback(every=save_after_this_many_epochs, path='/workspace/models/model', last_epoch_save = last_epoch_save)\n",
    "\n",
    "# Continue training the model with the custom callback\n",
    "learn_long.fine_tune(additional_epochs, base_lr=learning_rate, cbs=[save_model_callback])\n",
    "\n",
    "# Save the updated model at the end\n",
    "updated_model_path = f'/workspace/models/model_epoch{(last_epoch_save+additional_epochs)}.pkl'\n",
    "learn_long.export(updated_model_path)\n",
    "\n",
    "print(\"Training completed and model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_long = ClassificationInterpretation.from_learner(learn_long)\n",
    "interp_long.plot_confusion_matrix(normalize=True, title='Confusion Matrix', figsize=(12, 12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
